{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debasmitroy/Desktop/programming/agent-starter-1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/var/folders/nj/mkjg2k_d4hv0th92zft43hmw0000gn/T/ipykernel_75291/1801320634.py:2: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from utils.llms.langchain_openai import LangchainOpenaiJsonEngine, LangchainOpenaiSimpleChatEngine\n"
     ]
    }
   ],
   "source": [
    "from utils.llms.gemini import GeminiJsonEngine, GeminiSimpleChatEngine\n",
    "from utils.llms.langchain_openai import LangchainOpenaiJsonEngine, LangchainOpenaiSimpleChatEngine\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool is used to analyze the sentiment of a given text. The sentiment is analyzed based on the emotions of the text.\n",
    "    \"\"\"\n",
    "    happy: bool = Field(title=\"Happy\",description=\"The User is happy.\")\n",
    "    sad: bool = Field(title=\"Sad\",description=\"The User is sad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/debasmitroy/Desktop/programming/temp_deployment/key.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"openserve-0\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m2025-03-20 02:16:40,490 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project openserve-0, location us-central1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sad': False, 'happy': True}\n"
     ]
    }
   ],
   "source": [
    "gemini_sentiment_engine = GeminiJsonEngine(\n",
    "                                    model_name=\"gemini-2.0-flash-001\",\n",
    "                                    basemodel=Sentiment,\n",
    "                                    temperature=0.5,\n",
    "                                    max_output_tokens=256,\n",
    "                                    systemInstructions=None,\n",
    "                                    max_retries=5,\n",
    "                                    wait_time=30,\n",
    "                                    deployed_gcp=False\n",
    "                                    )\n",
    "\n",
    "# Not that good\n",
    "gemini_ans = gemini_sentiment_engine.run(\n",
    "    [\n",
    "        \"You are an AI assistant. Your task is to analyze the sentiment of the user's text.\",\n",
    "        \"Now analyze the sentiment of the user's text. Generate sentiment scores for anger, joy, and fear form the user's text. Use `Sentiment` as the base model. Stricly follow the arguments and return the result in the form of a JSON object.\",\n",
    "        \"User: I am happy. I am very happy today.\"\n",
    "    ]\n",
    ")\n",
    "print(gemini_ans[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m2025-03-20 02:18:33,112 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project openserve-0, location us-central1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gemini_sentiment_engine_simple = GeminiSimpleChatEngine(\n",
    "                                    model_name=\"gemini-2.0-flash-001\",\n",
    "                                    temperature=0.5,\n",
    "                                    max_output_tokens=256,\n",
    "                                    systemInstructions=None,\n",
    "                                    max_retries=5,\n",
    "                                    wait_time=30,\n",
    "                                    deployed_gcp=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I've analyzed the user's text (\"I am happy. I am very happy today.\") and here are the sentiment scores:\n",
      "\n",
      "*   **Joy:** 0.95\n",
      "*   **Anger:** 0.01\n",
      "*   **Fear:** 0.01\n"
     ]
    }
   ],
   "source": [
    "gemini_ans_simple = gemini_sentiment_engine_simple.run(\n",
    "    [\n",
    "        \"You are an AI assistant. Your task is to analyze the sentiment of the user's text.\",\n",
    "        \"Now analyze the sentiment of the user's text. Generate sentiment scores for anger, joy, and fear form the user's text.\",\n",
    "        \"User: I am happy. I am very happy today.\"\n",
    "    ]\n",
    ")\n",
    "print(gemini_ans_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain OpenAI Uage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debasmitroy/Desktop/programming/agent-starter-1/.venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:1547: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "langchain_sentiment_engine = LangchainOpenaiJsonEngine(\n",
    "                                        sampleBaseModel=Sentiment,\n",
    "                                        systemPromptText=\"You are an AI assistant. You are helping a user with a task. The user is asking you questions and you are answering them.\",\n",
    "                                        temperature=0.0,                    \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'happy': True, 'sad': False}\n"
     ]
    }
   ],
   "source": [
    "result = langchain_sentiment_engine.run(\"I am happy\")\n",
    "print(dict(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chat Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_sentiment_engine_simple = LangchainOpenaiSimpleChatEngine(\n",
    "                                        systemPromptText=\"You are an AI assistant. You are helping a user with a task. The user is asking you questions and you are answering them.\",\n",
    "                                        temperature=0.0,                    \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tools to run ...\n",
      "That's great to hear! Is there anything specific you would like help with or any questions you have?\n"
     ]
    }
   ],
   "source": [
    "result = langchain_sentiment_engine_simple.run(\"I am happy\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"openserve-0\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\" \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/debasmitroy/Desktop/programming/temp_deployment/key.json\"\n",
    "\n",
    "from utils.llms.gemini_imagegen import ImageGeneratorEngine\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_GENERATOR_ENGINE = ImageGeneratorEngine(number_of_images=1,\n",
    "        aspect_ratio=\"1:1\",\n",
    "        language=\"auto\",\n",
    "        safety_filter_level=\"block_some\",\n",
    "        person_generation=\"allow_adult\",\n",
    "        delay=30)\n",
    "\n",
    "prompts = \"\"\"Please generate a beautiful image of a sunset over the ocean.\"\"\"\n",
    "result = IMAGE_GENERATOR_ENGINE.run(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
